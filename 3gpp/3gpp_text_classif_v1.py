# -*- coding: utf-8 -*-
# 3gpp_text_classif_v1.py
# 2020.08.19
#---------------------------------------------
#  README:
#---------------------------------------------
# SOURCE DOCUMENT
# LTE; Evolved Universal Terrestrial Radio Access (E-UTRA) and Evolved Packet Core (EPC);
# User Equipment (UE) conformance specification; Part 1: Protocol conformance specification
# 3GPP TS 36.523-1
# https://portal.3gpp.org/desktopmodules/Specifications/SpecificationDetails.aspx?specificationId=2472
# 
# .\36523-1-f00.zip contains several *.DOC files 
#  One of them '36523-1-f00_s07_01.DOC' file is converted to '36523-1-f00_s07_01.txt' manually
#
# Two  *.TSV files were generated by functions in parse_3gpp_v2.py
# -- (1) 36523-1-f00_s07_01.tsv           DF with with/when/then columns
# -- (2) 36523-1-f00_s07_01_sent_lbl.tsv  DF with 'sentences' from WITH/ WHEN/ THEN (mapped to 0/1/2), sep='\t'
# Both TSV files are also in # 36523-1-f00_s07_01_sent_lbl.zip
#############################################################################
# INPUT DATA:
#     wd = 'C:\\Users\\Farid Khafizov\\Downloads\\\3gpp_data_files\\'
#     input_fn1 = wd + '36523-1-f00_s07_01.tsv'
#     input_fn2 = wd + '36523-1-f00_s07_01_sent_lbl.tsv'
#
#
# OUTPUT:
#    .\36523-1-f00_s07_01_clf_res.csv    

'''
print(d.columns)
txt = np.array(list(d['with'])    + list(d['when'])    + list(d['then']))
lbl = np.array([0]*len(d['with']) + [1]*len(d['when']) + [2]*len(d['then']) )
d2 = pd.DataFrame({'sentences':txt, 'labels':lbl})
print(d2.head())

out_fn = file_name.split('.')[0]+'_sent_lbl.tsv'
d2.to_csv(wd + out_fn, index=False, sep='\t', encoding='latin1')
# Test readability of saved file
f2 = pd.read_csv(wd + out_fn, sep='\t', encoding='latin1')
# compare = [ d2.sentences.loc[i] != f2.sentences.loc[i] for i in range(len(d2))]
compare = [ np.sum(d2.loc[i] != f2.loc[i]) for i in range(len(d2))]
print('If data matches, show 0:',  np.sum(compare) )
f2.shape
'''

#%%
import numpy as np
import pandas as pd
# import string
import random
#%%
fn = r'C:\Users\Farid Khafizov\Downloads\3gpp_data_files\36523-1-f00_s07_01.tsv'
out_fn = r'C:\Users\Farid Khafizov\Downloads\3gpp_data_files\36523-1-f00_s07_01_clf_res.csv'
d = pd.read_csv(fn, sep='\t', encoding='latin1')

def get_X_Y(d):
    txt = np.array(list(d['with'])    + list(d['when'])    + list(d['then']))
    lbl = np.array([0]*len(d['with']) + [1]*len(d['when']) + [2]*len(d['then']) )
    d2 = pd.DataFrame({'sentences':txt, 'labels':lbl})
    return txt, lbl, d2

#%% SPLIT DATA FRAME INTO TRAIN AND TEST
np.random.seed(seed=10)
idx = np.random.permutation(d.shape[0])
test_rows = random.sample( range(0,d.shape[0]), 3 ) 
test_rows=[0,1,2]
d_test = d.iloc[test_rows]
d_train = d.drop(test_rows)

X_train, y_train, d2_train = get_X_Y(d_train)
X_test,  y_test, d2_test  = get_X_Y(d_test)


#%% GENERATE TRAIN AND TEST SETS
'''
from sklearn.model_selection import train_test_split

assert len(lbl) == len(txt)

# Shuffle and split
np.random.seed(seed=10)
idx = np.random.permutation(len(txt))
data, labels = txt[idx], lbl[idx]
df2=pd.DataFrame({'sentences':data,'labels':labels})
X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)
'''
#%%
from sklearn.feature_extraction.text import CountVectorizer
count_vect = CountVectorizer()
X_train_counts = count_vect.fit_transform(X_train)   # Plain Train set
X_test_counts  = count_vect.transform(X_test)


#%%
models = ['NB', 'NB+TF', 'NB+TFIDF', 'SVM', 'SVM+TF', 'SVM+TFIDF', 'XGB', 'XGB+TF', 'XGB+TFIDF']
oacs = np.zeros(len(models))    
oac_df = pd.DataFrame( {'oac':oacs}, index=models )
oac_df    
#%%
# !pip install xgboost
#%% XGBoost: XGB 
import xgboost as xgb
import warnings
warnings.filterwarnings(module='xgboost*', action='ignore', category=DeprecationWarning)

xgbmodel = xgb.XGBClassifier( max_depth=1, n_estimators=3000, learning_rate=0.01 ).fit(X_train_counts, y_train)
predicted = xgbmodel.predict(X_test_counts)
res=np.mean(predicted == y_test)
print(res)
#oac_df.loc['XGB']=res

#%%


#%%   COPIED FROM
# https://gitlab.verizon.com/atf/atf-development/atf-data-sciences/-/blob/master/ML_models/atf_xgb_classifier.py

def compare_classifiers(d2, test_fraction, seedval):
#    VALIDATION_SPLIT = 0.3
    np.random.seed(seed=seedval)
    indices = np.arange(d2.shape[0]) # get sequence of row index
    np.random.shuffle(indices) # shuffle the row indexes
    data   = d2['sentences'][indices] # shuffle data/product-titles/x-axis
    labels = d2['labels'][indices]
    #
    from sklearn.model_selection import train_test_split
    X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=test_fraction, random_state=42)
    
#    #%% COMPARE  TRAIN  AND  TEST  SET DISTRIBUTIONS
#    vdf=pd.concat([y_train.value_counts(normalize=True).round(3) * 100, 
#                   y_test.value_counts(normalize=True).round(3) * 100],
#    sort =False, axis=1,ignore_index=True )
#    vdf.columns = ['train','test']
#    vdf.to_csv(wd+"comp_train_and_test_lables.csv")
    
    #%   ========================================================
    # INITIALIZE OAC SUMMARY TABLE
    import numpy
    models = ['NB', 'NB+TF', 'NB+TFIDF', 'SVM', 'SVM+TF', 'SVM+TFIDF', 'XGB', 'XGB+TF', 'XGB+TFIDF']
    oacs = numpy.zeros(len(models))    
    oac_df = pd.DataFrame( {'oac':oacs}, index=models )
    oac_df    
    
    
    #%  DEFINE THREE TRAIN SETS
    from sklearn.feature_extraction.text import CountVectorizer
    count_vect = CountVectorizer()
    X_train_counts = count_vect.fit_transform(X_train)   # Plain Train set
    X_test_counts  = count_vect.transform(X_test)
    
    #%
    from sklearn.feature_extraction.text import TfidfTransformer
    tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)
    X_train_tf = tf_transformer.transform(X_train_counts)  # TF train set 
    X_test_tf  = tf_transformer.transform(X_test_counts)
    #%
    tfidf_transformer = TfidfTransformer()
    X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)  # TFIDF Train set
    X_test_tfidf  = tfidf_transformer.transform(X_test_counts)
    
    #% XGBoost: XGB 
    import xgboost as xgb
    import warnings
    warnings.filterwarnings(module='xgboost*', action='ignore', category=DeprecationWarning)
    
    #xgbmodel = xgb.XGBClassifier( max_depth=3, n_estimators=300, learning_rate=0.05 ).fit(X_train_counts, y_train)
    xgbmodel = xgb.XGBClassifier( max_depth=1, n_estimators=3000, learning_rate=0.01 ).fit(X_train_counts, y_train)
    predicted = xgbmodel.predict(X_test_counts)
    res=np.mean(predicted == y_test)
    oac_df.loc['XGB']=res
    print('XGB', res)
    
    #% XGBoost: XGB + TF
    #xgbmodel = xgb.XGBClassifier( max_depth=3, n_estimators=300, learning_rate=0.05 ).fit(X_train_tf, y_train)
    xgbmodel = xgb.XGBClassifier( max_depth=1, n_estimators=3000, learning_rate=0.01 ).fit(X_train_tf, y_train)
    predicted = xgbmodel.predict(X_test_tf)
    res=np.mean(predicted == y_test)
    oac_df.loc['XGB+TF']=res
    print('XGB+TF', res)
    
    #% XGB+TFIDF
    #xgbmodel = xgb.XGBClassifier( max_depth=3, n_estimators=300, learning_rate=0.05 ).fit(X_train_tfidf, y_train)
    xgbmodel = xgb.XGBClassifier( max_depth=1, n_estimators=3000, learning_rate=0.01 ).fit(X_train_tfidf, y_train)
    predicted = xgbmodel.predict(X_test_tfidf)
    res=np.mean(predicted == y_test)
    oac_df.loc['XGB+TFIDF']=res
    print('XGB+TFIDF', res)
    
    #% Plain NB Classifier
    from sklearn.naive_bayes import MultinomialNB
    #clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)
    from sklearn.pipeline import Pipeline
    text_clf = Pipeline([
        ('vect', CountVectorizer()),
        #('tfidf', TfidfTransformer()),
        ('clf', MultinomialNB()),])
    text_clf.fit(X_train, y_train)
    predicted = text_clf.predict(X_test)
    res=np.mean(predicted == y_test)
    oac_df.loc['NB']=res
    print('NB', res)
    
    #% NB iwth TF
    # TfidfTransformer(use_idf=False)
    text_clf = Pipeline([
        ('vect', CountVectorizer()),
        ('tfidf', TfidfTransformer(use_idf=False)),
        ('clf', MultinomialNB()),])
    text_clf.fit(X_train, y_train)
    predicted = text_clf.predict(X_test)
    res=np.mean(predicted == y_test)
    oac_df.loc['NB+TF']=res
    print('NB+TF', res)

    #%
#    lbls=[ x for x in set(labels)]
#    print(lbls)
#    cf = cmdf(y_test, predicted, lbls)
#    cf.to_csv(wd+'xgb_tf_cf.csv')
    
    #% NB with TFIDF
    text_clf = Pipeline([
        ('vect', CountVectorizer()),
        ('tfidf', TfidfTransformer(use_idf=True)),
        ('clf', MultinomialNB()),])
    text_clf.fit(X_train, y_train)
    predicted = text_clf.predict(X_test)
    res=np.mean(predicted == y_test)
    oac_df.loc['NB+TFIDF']=res
    print('NB+TFIDF', res)


    
    #% Plain SVM
    from sklearn.linear_model import SGDClassifier    
    text_clf = Pipeline([
        ('vect', CountVectorizer()),
    #     ('tfidf', TfidfTransformer()),
        ('clf', SGDClassifier(loss='hinge', penalty='l2',
                              alpha=1e-3, random_state=42,
                              max_iter=5, tol=None)), ])
    text_clf.fit(X_train, y_train)
    predicted = text_clf.predict(X_test)
    res=np.mean(predicted == y_test)
    oac_df.loc['SVM']=res
    print('SVM', res)

    
    #% SVM with TF
    text_clf = Pipeline([
        ('vect', CountVectorizer()),
        ('tfidf', TfidfTransformer(use_idf=False)),
        ('clf',  SGDClassifier(loss='hinge', penalty='l2',
                              alpha=1e-3, random_state=42,
                              max_iter=5, tol=None)), ])
    text_clf.fit(X_train, y_train)
    predicted = text_clf.predict(X_test)
    res=np.mean(predicted == y_test)
    oac_df.loc['SVM+TF']=res
    print('SVM+TF', res)
    
    #% SVM with TFIDF
    text_clf = Pipeline([
        ('vect', CountVectorizer()),
        ('tfidf', TfidfTransformer()),
        ('clf', SGDClassifier(loss='hinge', penalty='l2',
                              alpha=1e-3, random_state=42,
                              max_iter=5, tol=None)), ])
    text_clf.fit(X_train, y_train)
    predicted = text_clf.predict(X_test)
    res=np.mean(predicted == y_test)
    oac_df.loc['SVM+TFIDF']=res
    print('SVM+TFIDF', res)
    
    return oac_df    
    
#========================================================================    
    
#%%
rr = compare_classifiers(d2=d2_train, test_fraction=0.2, seedval=30)

for k in range(1,8):
    print(k)
    oac_df = compare_classifiers( d2=d2_train, test_fraction=0.2, seedval=10*k)
    oac_df.columns = [oac_df.columns[0]+str(k)]
    rr = pd.concat([rr, oac_df], axis=1)
    
#%% Delete col with all zeros
# resres.__delitem__('oac')    
rr['mean'] = rr.mean(axis=1)
rr['std']  = rr.iloc[:,0:8].std(axis=1)
rr = round(rr,2)
#%%

rr.to_csv(out_fn, sep=',')

